{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0   1         1         1         0         0         1         1         0   \n",
      "1   2         1         0         0         0         0         0         0   \n",
      "2   3         1         1         1         0         1         1         0   \n",
      "3   4         0         0         0         0         0         0         0   \n",
      "4   5         0         0         0         1         0         0         0   \n",
      "\n",
      "   A8_Score  A9_Score  ...        age  gender       ethnicity jaundice austim  \\\n",
      "0         0         1  ...  15.599481       m  White-European      yes     no   \n",
      "1         1         0  ...  27.181099       m           Asian       no     no   \n",
      "2         1         1  ...  31.643906       m  White-European      yes     no   \n",
      "3         0         0  ...  25.369210       m               ?       no     no   \n",
      "4         0         0  ...   9.078580       m               ?       no     no   \n",
      "\n",
      "  contry_of_res used_app_before     result     age_desc relation  \n",
      "0         India              no  12.399055  18 and more     Self  \n",
      "1        Mexico              no   6.551598  18 and more     Self  \n",
      "2         Egypt              no   3.180663  18 and more     Self  \n",
      "3         India              no   2.220766  18 and more     Self  \n",
      "4         Italy              no   7.252028  18 and more     Self  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/train.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               200 non-null    int64  \n",
      " 1   A1_Score         200 non-null    int64  \n",
      " 2   A2_Score         200 non-null    int64  \n",
      " 3   A3_Score         200 non-null    int64  \n",
      " 4   A4_Score         200 non-null    int64  \n",
      " 5   A5_Score         200 non-null    int64  \n",
      " 6   A6_Score         200 non-null    int64  \n",
      " 7   A7_Score         200 non-null    int64  \n",
      " 8   A8_Score         200 non-null    int64  \n",
      " 9   A9_Score         200 non-null    int64  \n",
      " 10  A10_Score        200 non-null    int64  \n",
      " 11  age              200 non-null    float64\n",
      " 12  gender           200 non-null    object \n",
      " 13  ethnicity        200 non-null    object \n",
      " 14  jaundice         200 non-null    object \n",
      " 15  austim           200 non-null    object \n",
      " 16  contry_of_res    200 non-null    object \n",
      " 17  used_app_before  200 non-null    object \n",
      " 18  result           200 non-null    float64\n",
      " 19  age_desc         200 non-null    object \n",
      " 20  relation         200 non-null    object \n",
      "dtypes: float64(2), int64(11), object(8)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#print(df.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>200.0</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>57.879185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.498213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.500628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.498742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A6_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.474898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.494797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_Score</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.481205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>200.0</td>\n",
       "      <td>26.074568</td>\n",
       "      <td>14.517024</td>\n",
       "      <td>4.781474</td>\n",
       "      <td>16.152524</td>\n",
       "      <td>22.717970</td>\n",
       "      <td>32.004413</td>\n",
       "      <td>77.110749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.671369</td>\n",
       "      <td>4.709994</td>\n",
       "      <td>-5.655613</td>\n",
       "      <td>5.611695</td>\n",
       "      <td>9.804165</td>\n",
       "      <td>12.487160</td>\n",
       "      <td>15.731361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std       min        25%         50%  \\\n",
       "ID         200.0  100.500000  57.879185  1.000000  50.750000  100.500000   \n",
       "A1_Score   200.0    0.575000   0.495584  0.000000   0.000000    1.000000   \n",
       "A2_Score   200.0    0.555000   0.498213  0.000000   0.000000    1.000000   \n",
       "A3_Score   200.0    0.475000   0.500628  0.000000   0.000000    0.000000   \n",
       "A4_Score   200.0    0.425000   0.495584  0.000000   0.000000    0.000000   \n",
       "A5_Score   200.0    0.450000   0.498742  0.000000   0.000000    0.000000   \n",
       "A6_Score   200.0    0.340000   0.474898  0.000000   0.000000    0.000000   \n",
       "A7_Score   200.0    0.420000   0.494797  0.000000   0.000000    0.000000   \n",
       "A8_Score   200.0    0.545000   0.499220  0.000000   0.000000    1.000000   \n",
       "A9_Score   200.0    0.540000   0.499648  0.000000   0.000000    1.000000   \n",
       "A10_Score  200.0    0.640000   0.481205  0.000000   0.000000    1.000000   \n",
       "age        200.0   26.074568  14.517024  4.781474  16.152524   22.717970   \n",
       "result     200.0    8.671369   4.709994 -5.655613   5.611695    9.804165   \n",
       "\n",
       "                  75%         max  \n",
       "ID         150.250000  200.000000  \n",
       "A1_Score     1.000000    1.000000  \n",
       "A2_Score     1.000000    1.000000  \n",
       "A3_Score     1.000000    1.000000  \n",
       "A4_Score     1.000000    1.000000  \n",
       "A5_Score     1.000000    1.000000  \n",
       "A6_Score     1.000000    1.000000  \n",
       "A7_Score     1.000000    1.000000  \n",
       "A8_Score     1.000000    1.000000  \n",
       "A9_Score     1.000000    1.000000  \n",
       "A10_Score    1.000000    1.000000  \n",
       "age         32.004413   77.110749  \n",
       "result      12.487160   15.731361  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting data for any anomolies for data cleaning \n",
    "We can see in the output below that there are discrepencies such as 'other' '?' and 'Others' which probably are for some unkown value and are substituted as an indicator of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "ID                   int64\n",
      "A1_Score             int64\n",
      "A2_Score             int64\n",
      "A3_Score             int64\n",
      "A4_Score             int64\n",
      "A5_Score             int64\n",
      "A6_Score             int64\n",
      "A7_Score             int64\n",
      "A8_Score             int64\n",
      "A9_Score             int64\n",
      "A10_Score            int64\n",
      "age                float64\n",
      "gender              object\n",
      "ethnicity           object\n",
      "jaundice            object\n",
      "austim              object\n",
      "contry_of_res       object\n",
      "used_app_before     object\n",
      "result             float64\n",
      "age_desc            object\n",
      "relation            object\n",
      "dtype: object\n",
      "\n",
      "Value counts for gender:\n",
      "gender\n",
      "m    125\n",
      "f     75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for ethnicity:\n",
      "ethnicity\n",
      "White-European     66\n",
      "?                  54\n",
      "Middle Eastern     27\n",
      "Asian              17\n",
      "South Asian         9\n",
      "Pasifika            8\n",
      "Others              7\n",
      "Latino              4\n",
      "Turkish             3\n",
      "Black               3\n",
      "Hispanic            2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for jaundice:\n",
      "jaundice\n",
      "no     146\n",
      "yes     54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for austim:\n",
      "austim\n",
      "no     171\n",
      "yes     29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for contry_of_res:\n",
      "contry_of_res\n",
      "United States           33\n",
      "India                   32\n",
      "United Kingdom          19\n",
      "New Zealand             17\n",
      "Jordan                  15\n",
      "United Arab Emirates    11\n",
      "Canada                  11\n",
      "Australia                8\n",
      "Afghanistan              5\n",
      "Netherlands              4\n",
      "Malaysia                 4\n",
      "Russia                   4\n",
      "Austria                  3\n",
      "France                   3\n",
      "Iran                     3\n",
      "Italy                    3\n",
      "Egypt                    2\n",
      "Sri Lanka                2\n",
      "Germany                  2\n",
      "Viet Nam                 2\n",
      "Bahamas                  2\n",
      "Bolivia                  2\n",
      "Mexico                   1\n",
      "Uruguay                  1\n",
      "Spain                    1\n",
      "Burundi                  1\n",
      "Lebanon                  1\n",
      "Pakistan                 1\n",
      "Iceland                  1\n",
      "Aruba                    1\n",
      "Ireland                  1\n",
      "Tonga                    1\n",
      "Philippines              1\n",
      "Azerbaijan               1\n",
      "Czech Republic           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for used_app_before:\n",
      "used_app_before\n",
      "no     192\n",
      "yes      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for age_desc:\n",
      "age_desc\n",
      "18 and more    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for relation:\n",
      "relation\n",
      "Self                        180\n",
      "Parent                        8\n",
      "?                             6\n",
      "Relative                      2\n",
      "Others                        2\n",
      "Health care professional      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "#checking data types\n",
    "print(df.dtypes)\n",
    "\n",
    "#checking inconsistencies in each column of data\n",
    "categorical_columns = ['gender', 'ethnicity', 'jaundice', 'austim', 'contry_of_res', 'used_app_before', 'age_desc', 'relation']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    print(df[col].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data up after checking the descrepensies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               200 non-null    int64  \n",
      " 1   A1_Score         200 non-null    int64  \n",
      " 2   A2_Score         200 non-null    int64  \n",
      " 3   A3_Score         200 non-null    int64  \n",
      " 4   A4_Score         200 non-null    int64  \n",
      " 5   A5_Score         200 non-null    int64  \n",
      " 6   A6_Score         200 non-null    int64  \n",
      " 7   A7_Score         200 non-null    int64  \n",
      " 8   A8_Score         200 non-null    int64  \n",
      " 9   A9_Score         200 non-null    int64  \n",
      " 10  A10_Score        200 non-null    int64  \n",
      " 11  age              200 non-null    float64\n",
      " 12  gender           200 non-null    object \n",
      " 13  ethnicity        200 non-null    object \n",
      " 14  jaundice         200 non-null    int64  \n",
      " 15  austim           200 non-null    int64  \n",
      " 16  contry_of_res    200 non-null    object \n",
      " 17  used_app_before  200 non-null    int64  \n",
      " 18  result           200 non-null    float64\n",
      " 19  age_desc         200 non-null    object \n",
      " 20  relation         200 non-null    object \n",
      "dtypes: float64(2), int64(14), object(5)\n",
      "memory usage: 32.9+ KB\n",
      "None\n",
      "                 count        mean        std       min        25%  \\\n",
      "ID               200.0  100.500000  57.879185  1.000000  50.750000   \n",
      "A1_Score         200.0    0.575000   0.495584  0.000000   0.000000   \n",
      "A2_Score         200.0    0.555000   0.498213  0.000000   0.000000   \n",
      "A3_Score         200.0    0.475000   0.500628  0.000000   0.000000   \n",
      "A4_Score         200.0    0.425000   0.495584  0.000000   0.000000   \n",
      "A5_Score         200.0    0.450000   0.498742  0.000000   0.000000   \n",
      "A6_Score         200.0    0.340000   0.474898  0.000000   0.000000   \n",
      "A7_Score         200.0    0.420000   0.494797  0.000000   0.000000   \n",
      "A8_Score         200.0    0.545000   0.499220  0.000000   0.000000   \n",
      "A9_Score         200.0    0.540000   0.499648  0.000000   0.000000   \n",
      "A10_Score        200.0    0.640000   0.481205  0.000000   0.000000   \n",
      "age              200.0   26.074568  14.517024  4.781474  16.152524   \n",
      "jaundice         200.0    0.270000   0.445074  0.000000   0.000000   \n",
      "austim           200.0    0.145000   0.352984  0.000000   0.000000   \n",
      "used_app_before  200.0    0.040000   0.196451  0.000000   0.000000   \n",
      "result           200.0    8.671369   4.709994 -5.655613   5.611695   \n",
      "\n",
      "                        50%         75%         max  \n",
      "ID               100.500000  150.250000  200.000000  \n",
      "A1_Score           1.000000    1.000000    1.000000  \n",
      "A2_Score           1.000000    1.000000    1.000000  \n",
      "A3_Score           0.000000    1.000000    1.000000  \n",
      "A4_Score           0.000000    1.000000    1.000000  \n",
      "A5_Score           0.000000    1.000000    1.000000  \n",
      "A6_Score           0.000000    1.000000    1.000000  \n",
      "A7_Score           0.000000    1.000000    1.000000  \n",
      "A8_Score           1.000000    1.000000    1.000000  \n",
      "A9_Score           1.000000    1.000000    1.000000  \n",
      "A10_Score          1.000000    1.000000    1.000000  \n",
      "age               22.717970   32.004413   77.110749  \n",
      "jaundice           0.000000    1.000000    1.000000  \n",
      "austim             0.000000    0.000000    1.000000  \n",
      "used_app_before    0.000000    0.000000    1.000000  \n",
      "result             9.804165   12.487160   15.731361  \n",
      "\n",
      "Value counts for gender:\n",
      "gender\n",
      "m    125\n",
      "f     75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for ethnicity:\n",
      "ethnicity\n",
      "White-European     66\n",
      "Others             61\n",
      "Middle Eastern     27\n",
      "Asian              17\n",
      "South Asian         9\n",
      "Pasifika            8\n",
      "Latino              4\n",
      "Turkish             3\n",
      "Black               3\n",
      "Hispanic            2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for jaundice:\n",
      "jaundice\n",
      "0    146\n",
      "1     54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for austim:\n",
      "austim\n",
      "0    171\n",
      "1     29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for contry_of_res:\n",
      "contry_of_res\n",
      "United States           33\n",
      "India                   32\n",
      "United Kingdom          19\n",
      "New Zealand             17\n",
      "Jordan                  15\n",
      "United Arab Emirates    11\n",
      "Canada                  11\n",
      "Australia                8\n",
      "Afghanistan              5\n",
      "Netherlands              4\n",
      "Malaysia                 4\n",
      "Russia                   4\n",
      "Austria                  3\n",
      "France                   3\n",
      "Iran                     3\n",
      "Italy                    3\n",
      "Egypt                    2\n",
      "Sri Lanka                2\n",
      "Germany                  2\n",
      "Viet Nam                 2\n",
      "Bahamas                  2\n",
      "Bolivia                  2\n",
      "Mexico                   1\n",
      "Uruguay                  1\n",
      "Spain                    1\n",
      "Burundi                  1\n",
      "Lebanon                  1\n",
      "Pakistan                 1\n",
      "Iceland                  1\n",
      "Aruba                    1\n",
      "Ireland                  1\n",
      "Tonga                    1\n",
      "Philippines              1\n",
      "Azerbaijan               1\n",
      "Czech Republic           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for used_app_before:\n",
      "used_app_before\n",
      "0    192\n",
      "1      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for age_desc:\n",
      "age_desc\n",
      "18 and more    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for relation:\n",
      "relation\n",
      "Self                        180\n",
      "Parent                        8\n",
      "Others                        8\n",
      "Relative                      2\n",
      "Health care professional      2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedh\\AppData\\Local\\Temp\\ipykernel_20312\\3866093031.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n"
     ]
    }
   ],
   "source": [
    "df = df.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe().T)\n",
    "#checking if data has been cleaned \n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autismPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
